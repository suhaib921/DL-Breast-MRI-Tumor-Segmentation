{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import glob\n",
    "#from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from utils import get_model, set_seed\n",
    "#from denoise_traditional import denoise_gaussian, denoise_nlm\n",
    "\n",
    "#from monai.transforms import Compose, RandFlip, RandRotate, RandGaussianNoise, RandAdjustContrast, ScaleIntensity\n",
    "\n",
    "from unet import UNet\n",
    "from PIL import Image\n",
    "\n",
    "from train import train_seg\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   \n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT DATA:\n",
    "TRAINING_DATA_PATH = \"/home/suhkth/Desktop/DL-Breast-MRI-Tumor-Segmentation/Model/google_colab/labeled_mri_gray\"\n",
    "\n",
    "IMAGE_PATHS = glob.glob(\"/home/suhkth/Desktop/DL-Breast-MRI-Tumor-Segmentation/Model/google_colab/labeled_mri_gray/*_post.png\")\n",
    "MASK_PATHS = [f.replace(\"_post.png\", \"_subtraction_label.png\") for f in IMAGE_PATHS]\n",
    "\n",
    "split_idx = int(0.8 * len(IMAGE_PATHS)) # 80% training, 20% testing\n",
    "\n",
    "TRAINING_IMAGE_PATHS = IMAGE_PATHS[:split_idx]\n",
    "TESTING_IMAGE_PATHS = IMAGE_PATHS[split_idx:]\n",
    "\n",
    "TRAINING_MASK_PATHS = MASK_PATHS[:split_idx]\n",
    "TESTING_MASK_PATHS = MASK_PATHS[split_idx:]\n",
    "print(IMAGE_PATHS)\n",
    "print(MASK_PATHS)\n",
    "print(len(TRAINING_IMAGE_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class segmentationDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")  # Implement your image loading\n",
    "        \n",
    "        image = np.array(image) / 255.0  # Normalize to [0, 1] here!        # Convert to PyTorch tensor and permute dimensions\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()  # [C, H, W]\n",
    "        #mask = Image.open(self.image_paths[idx])\n",
    "        #MASK MIGHT BE ISSUE\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]).convert(\"L\"))\n",
    "        mask = (mask > 0).astype(np.int64)  # Convert 255 → 1, keep 0 as 0\n",
    "        mask = np.expand_dims(mask, axis=0)  # Shape: [1, H, W]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "            \n",
    "        return image, mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data_train = segmentationDataSet(TRAINING_IMAGE_PATHS, TRAINING_MASK_PATHS)\n",
    "breast_data_test = segmentationDataSet(TESTING_IMAGE_PATHS, TESTING_MASK_PATHS)\n",
    "\n",
    "trainloader = utils.DataLoader(breast_data_train,\n",
    "                                batch_size = 4, \n",
    "                                shuffle = False,\n",
    "                                num_workers = 0,\n",
    "                                drop_last = True)\n",
    "\n",
    "testloader = utils.DataLoader(breast_data_test,\n",
    "                                batch_size = 4, \n",
    "                                shuffle = False,\n",
    "                                num_workers = 0,\n",
    "                                drop_last = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = trainloader.dataset[0]  # Get first sample\n",
    "print(type(sample))  # Check what type it is\n",
    "#print(len(sample))  # Check if it's a tuple/list and how many elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg, testlabel = next(iter(trainloader))\n",
    "\n",
    "print(testimg.shape)\n",
    "print(testlabel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "images, masks = next(iter(trainloader))\n",
    "\n",
    "# Convert tensors to numpy arrays and denormalize if needed\n",
    "images = images.numpy().transpose(0, 2, 3, 1)  # [B, C, H, W] → [B, H, W, C] for plotting\n",
    "masks = masks.numpy().squeeze(1)  # [B, 1, H, W] → [B, H, W] (remove channel dim)\n",
    "\n",
    "# Plot first 4 samples in the batch\n",
    "fig, axes = plt.subplots(4, 2, figsize=(10, 20))  # 4 rows, 2 columns (image + mask)\n",
    "\n",
    "for i in range(4):\n",
    "    # Plot image\n",
    "    axes[i, 0].imshow(images[i])\n",
    "    axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    # Plot mask (binary or grayscale)\n",
    "    axes[i, 1].imshow(masks[i], cmap=\"gray\")  # Use 'gray' colormap for masks\n",
    "    axes[i, 1].set_title(f\"Mask {i+1}\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = UNet(in_channels=3, out_channels=1, init_features=64)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Combines sigmoid and binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/home/suhkth/Desktop/DL-Breast-MRI-Tumor-Segmentation/Model/first_trained_model.pth\", weights_only=False ,map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(testloader))\n",
    "img = img.float().to(device)\n",
    "\n",
    "model.eval()  # Set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    output = model(img)  # Raw model output\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output min/max:\", output.min(), output.max())\n",
    "print(\"Output sample:\", output[0, :3, :3, :3])  # First image, first 3 classes, 3x3 pixels\n",
    "\n",
    "threshold = 0.5\n",
    "binary_pred = (output > threshold).float()  # Shape: [4, 1, 300, 300]\n",
    "\n",
    "# Visualize\n",
    "pred_mask = binary_pred[0, 0].cpu().numpy()  # Shape: [300, 300]\n",
    "plt.imshow(pred_mask, cmap='gray')\n",
    "plt.title(\"Binary Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "img, label = next(data_iter)  # Gets the next batch (different each run)\n",
    "with torch.no_grad():\n",
    "    output = model(img.float().to(device))\n",
    "\n",
    "# Binary thresholding\n",
    "pred_mask = (output > 0.5).float()\n",
    "\n",
    "# Select first image in batch\n",
    "img_vis = img[0].cpu().permute(1, 2, 0)  # CHW → HWC for plotting\n",
    "pred_vis = pred_mask[0, 0].cpu().numpy()  # Shape: [300, 300]\n",
    "label_vis = label[0].squeeze(0).cpu().numpy()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(img_vis)\n",
    "plt.title(\"Input\")\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(pred_vis, cmap='gray')\n",
    "plt.title(\"Prediction\")\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(label_vis, cmap='gray')\n",
    "plt.title(\"Ground Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weightsa.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali\n",
    "\n",
    "checkpoint = torch.load('model_weights_8_21_34_50_l2_1e-3.pth')\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()\n",
    "\n",
    "breast_data_inf = BreastDataset_seg(time_point,train_file_dir,train_val=\"inf\",one_or_twoDim=False,denoise=if_denoise, seg_num=seg_parts)\n",
    "\n",
    "\n",
    "infloader = utils.DataLoader(breast_data_inf ,\n",
    "                                batch_size = 1, \n",
    "                                shuffle = False,\n",
    "                                num_workers = 0,\n",
    "                                drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelme_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
