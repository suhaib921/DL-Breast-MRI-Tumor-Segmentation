{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import CustomDataset, JointTransform\n",
    "from unet_model import UNet\n",
    "from train import train_model\n",
    "from scipy.optimize import curve_fit\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log part\n",
    "def log_creater(logger_file_path):\n",
    "    if not os.path.exists(logger_file_path):\n",
    "        os.makedirs(logger_file_path)\n",
    "    log_name = '{}.log'.format(time.strftime('%Y-%m-%d-%H-%M'))\n",
    "    final_log_file = os.path.join(logger_file_path, log_name)\n",
    "\n",
    "    logger = logging.getLogger()  # 设定日志对象\n",
    "    logger.setLevel(logging.INFO)  # 设定日志等级\n",
    "\n",
    "    file_handler = logging.FileHandler(final_log_file)  # 文件输出\n",
    "    console_handler = logging.StreamHandler()  # 控制台输出\n",
    "\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s %(levelname)s: %(message)s \"\n",
    "    )\n",
    "\n",
    "    file_handler.setFormatter(formatter)  # 设置文件输出格式\n",
    "    console_handler.setFormatter(formatter)  # 设施控制台输出格式\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "train_file_dir = 'C:\\\\Users\\\\LJY\\\\Desktop\\\\研一后\\\\2024kth比赛\\\\20240413\\\\testcode\\\\'\n",
    "file_Resultdir='./Result_unet/'\n",
    "fname_gt ='_IVIMParam.npy'\n",
    "fname_tissue ='_TissueType.npy'\n",
    "fname_noisyDWIk = '_NoisyDWIk.npy'\n",
    "model_name=  \"UNet\"\n",
    "\n",
    "logger = log_creater('./log/')\n",
    "\n",
    "seg_parts = 8\n",
    "\n",
    "set_seed(seed=10)\n",
    "\n",
    "b_values = np.array([0, 5, 50, 100, 200, 500, 800, 1000])\n",
    "loss_type = \"L1L2\"\n",
    "\n",
    "\n",
    "\n",
    "#==========\n",
    "\n",
    "learn_rate = 0.00015\n",
    "batch_size = 8\n",
    "time_point = 7\n",
    "#==========\n",
    "\n",
    "# Network\n",
    "if time_point==7:\n",
    "    b_values_no0 = torch.FloatTensor(b_values[1:])\n",
    "else:\n",
    "    b_values_no0 = torch.FloatTensor(b_values)\n",
    "net = get_model(model_name, seg_parts, device)\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr = learn_rate, weight_decay=1e-3)  \n",
    "# use crossentropyloss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# # use focalloss\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, gamma=2.0, alpha=None):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha  # 可选的 alpha，用于处理类别不平衡\n",
    "\n",
    "#     def forward(self, outputs, targets):\n",
    "#         # 使用 CrossEntropyLoss 计算每个样本的损失\n",
    "#         ce_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)  # 计算概率\n",
    "\n",
    "#         # 如果有 alpha，应用类别平衡\n",
    "#         if self.alpha is not None:\n",
    "#             at = self.alpha[targets]\n",
    "#             ce_loss = at * ce_loss\n",
    "\n",
    "#         # 计算 Focal Loss\n",
    "#         focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "#         return focal_loss.mean()\n",
    "# criterion = FocalLoss(gamma=2.0, alpha=torch.tensor([0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.15, 0.3]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg parts =  8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"seg parts = \", seg_parts)\n",
    "\n",
    "train_transforms = Compose([\n",
    "    RandFlip(spatial_axis=[0], prob=0.5),\n",
    "    RandFlip(spatial_axis=[1], prob=0.5),\n",
    "    # RandRotate(range_x=np.pi/12, prob=0.2)\n",
    "    # RandGaussianNoise(prob=0.5, mean=0.0, std=0.01),\n",
    "    # RandAdjustContrast(prob=0.3, gamma=(0.9, 1.1)),\n",
    "    # ScaleIntensity(minv=0.9, maxv=1.1)\n",
    "])\n",
    "\n",
    "breast_data_train = BreastDataset_seg(time_point,train_file_dir,train_val=\"train\",one_or_twoDim=False,denoise=if_denoise, seg_num=seg_parts, transform=None)\n",
    "breast_data_val = BreastDataset_seg(time_point,train_file_dir,train_val=\"val\",one_or_twoDim=False,denoise=if_denoise, seg_num=seg_parts)\n",
    "\n",
    "\n",
    "trainloader = utils.DataLoader(breast_data_train ,\n",
    "                                batch_size = batch_size, \n",
    "                                shuffle = False,\n",
    "                                num_workers = 0,\n",
    "                                drop_last = True)\n",
    "\n",
    "valloader = utils.DataLoader(breast_data_val,\n",
    "                                batch_size = 1, \n",
    "                                shuffle = False,\n",
    "                                num_workers = 0,\n",
    "                                drop_last = False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimg, testlabel = next(iter(valloader))\n",
    "\n",
    "print(testimg.shape)\n",
    "plt.figure()\n",
    "\n",
    "for i in range(7):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(testimg[0,i,:,:])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(7):\n",
    "    plt.imshow(testlabel[0,:,:])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(7):\n",
    "    plt.imshow(testimg[0,i,:,:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model, results = train_seg(net, trainloader, valloader, criterion, optimizer, device, num_epochs = epochs, logger = logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali\n",
    "img, label = next(iter(valloader))\n",
    "\n",
    "pred = model(img.float().to(device))\n",
    "\n",
    "pred = pred.argmax(1).squeeze().cpu()\n",
    "label = label.squeeze().cpu()\n",
    "print(pred.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pred)\n",
    "plt.title(\"pred\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(label)\n",
    "plt.title(\"label\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weightsa.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice = multiclass_dice_coeff(pred, label)\n",
    "# print(dice)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def multiclass_dice_score(preds, labels, num_classes, eps=1e-6):\n",
    "\n",
    "    labels_one_hot = F.one_hot(labels, num_classes).permute(0, 3, 1, 2)\n",
    "    \n",
    "    dice_scores = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = preds[:, cls, :, :]\n",
    "        label_cls = labels_one_hot[:, cls, :, :]\n",
    "        \n",
    "        intersection = (pred_cls * label_cls).sum(dim=(1, 2))\n",
    "        union = pred_cls.sum(dim=(1, 2)) + label_cls.sum(dim=(1, 2))\n",
    "        \n",
    "        dice = (2 * intersection + eps) / (union + eps)\n",
    "        dice_scores.append(dice.mean().item())\n",
    "    \n",
    "    return sum(dice_scores) / num_classes\n",
    "\n",
    "num_classes = seg_parts  \n",
    "\n",
    "p = F.one_hot(pred, seg_parts).permute(0, 3, 1, 2).float()\n",
    "\n",
    "dice_score = multiclass_dice_score(pred, label, num_classes)\n",
    "print(\"Multi-class Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vali\n",
    "\n",
    "checkpoint = torch.load('model_weights_8_21_34_50_l2_1e-3.pth')\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()\n",
    "\n",
    "breast_data_inf = BreastDataset_seg(time_point,train_file_dir,train_val=\"inf\",one_or_twoDim=False,denoise=if_denoise, seg_num=seg_parts)\n",
    "\n",
    "\n",
    "infloader = utils.DataLoader(breast_data_inf ,\n",
    "                                batch_size = 1, \n",
    "                                shuffle = False,\n",
    "                                num_workers = 0,\n",
    "                                drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "inf_loss, inf_accuracy, inf_dicelist = train.check_accuracy(net, infloader, criterion, device)\n",
    "print(inf_loss)\n",
    "print(inf_dicelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), results['train_loss'])\n",
    "plt.plot(range(0,epochs,2), results['val_loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelme_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
